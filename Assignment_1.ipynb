{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAKE2A6r9HBy9mDp92vrLo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedFayek2005/Ai_platform_/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.w00 = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
        "        self.b00 = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n",
        "\n",
        "        self.w01 = nn.Parameter(torch.tensor(0.6), requires_grad=True)\n",
        "        self.b01 = nn.Parameter(torch.tensor(-0.5), requires_grad=True)\n",
        "\n",
        "        self.w02 = nn.Parameter(torch.tensor(0.2), requires_grad=True)\n",
        "        self.b02 = nn.Parameter(torch.tensor(0.3), requires_grad=True)\n",
        "\n",
        "        self.w10_0 = nn.Parameter(torch.tensor(0.7), requires_grad=True)\n",
        "        self.w10_1 = nn.Parameter(torch.tensor(0.8), requires_grad=True)\n",
        "        self.w10_2 = nn.Parameter(torch.tensor(0.9), requires_grad=True)\n",
        "        self.b10   = nn.Parameter(torch.tensor(0.1), requires_grad=True)\n",
        "\n",
        "        self.w11_0 = nn.Parameter(torch.tensor(-0.5), requires_grad=True)\n",
        "        self.w11_1 = nn.Parameter(torch.tensor(0.4), requires_grad=True)\n",
        "        self.w11_2 = nn.Parameter(torch.tensor(0.6), requires_grad=True)\n",
        "        self.b11   = nn.Parameter(torch.tensor(-0.2), requires_grad=True)\n",
        "\n",
        "        self.w20 = nn.Parameter(torch.tensor(1.2), requires_grad=True)\n",
        "        self.b20 = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        inp = x\n",
        "\n",
        "        z1_0 = inp * self.w00 + self.b00\n",
        "        a1_0 = F.relu(z1_0)\n",
        "\n",
        "        z1_1 = inp * self.w01 + self.b01\n",
        "        a1_1 = F.relu(z1_1)\n",
        "\n",
        "        z1_2 = inp * self.w02 + self.b02\n",
        "        a1_2 = F.relu(z1_2)\n",
        "\n",
        "        print(\"Layer1 pre-acts:\", float(z1_0), float(z1_1), float(z1_2))\n",
        "        print(\"Layer1 outputs (ReLU):\", float(a1_0), float(a1_1), float(a1_2))\n",
        "\n",
        "        z2_0 = a1_0 * self.w10_0 + a1_1 * self.w10_1 + a1_2 * self.w10_2 + self.b10\n",
        "        a2_0 = torch.sigmoid(z2_0)\n",
        "\n",
        "        z2_1 = a1_0 * self.w11_0 + a1_1 * self.w11_1 + a1_2 * self.w11_2 + self.b11\n",
        "        a2_1 = torch.sigmoid(z2_1)\n",
        "\n",
        "        print(\"Layer2 pre-acts:\", float(z2_0), float(z2_1))\n",
        "        print(\"Layer2 outputs (Sigmoid):\", float(a2_0), float(a2_1))\n",
        "\n",
        "        combined = a2_0 + a2_1\n",
        "        combined_tanh = torch.tanh(combined)\n",
        "        print(\"Combined (sum):\", float(combined))\n",
        "        print(\"After Tanh:\", float(combined_tanh))\n",
        "\n",
        "        out = combined_tanh * self.w20 + self.b20\n",
        "        print(\"Final output (linear):\", float(out))\n",
        "\n",
        "        return out\n",
        "\n",
        "# ------------------ usage example ------------------\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "model = NN()\n",
        "\n",
        "output = model(x)\n",
        "output.backward()\n",
        "print(\"Gradient of output wrt x:\", x.grad.item())\n"
      ],
      "metadata": {
        "id": "z3TZtDGjCaNP",
        "outputId": "a9b94061-5b5a-495b-ea53-4de06aae2d8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer1 pre-acts: 2.0 0.7000000476837158 0.7000000476837158\n",
            "Layer1 outputs (ReLU): 2.0 0.7000000476837158 0.7000000476837158\n",
            "Layer2 pre-acts: 2.690000057220459 -0.4999999403953552\n",
            "Layer2 outputs (Sigmoid): 0.9364339113235474 0.3775406777858734\n",
            "Combined (sum): 1.3139746189117432\n",
            "After Tanh: 0.8652776479721069\n",
            "Final output (linear): 1.0383331775665283\n",
            "Gradient of output wrt x: 0.014490881934762001\n"
          ]
        }
      ]
    }
  ]
}